{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34877,"sourceType":"datasetVersion","datasetId":27352}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:37.887171Z\",\"iopub.execute_input\":\"2026-01-10T12:08:37.887487Z\",\"iopub.status.idle\":\"2026-01-10T12:08:39.394214Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:37.887461Z\",\"shell.execute_reply\":\"2026-01-10T12:08:39.393277Z\"}}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.decomposition import PCA\n\nfrom collections import Counter\nimport os\nimport time\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:39.395433Z\",\"iopub.execute_input\":\"2026-01-10T12:08:39.395891Z\",\"iopub.status.idle\":\"2026-01-10T12:08:39.401993Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:39.395861Z\",\"shell.execute_reply\":\"2026-01-10T12:08:39.400834Z\"}}\nCONFIG = {\n    # PCA\n    \"ENABLE_PCA\": True,\n    \"PCA_COMPONENTS\": 70,\n\n    # Per-model PCA toggles\n    \"USE_PCA_FOR_KNN\": True,\n    \"USE_PCA_FOR_SVM\": True,\n    \"USE_PCA_FOR_DT\": False,         # generally set false for DT\n\n    # KNN from scratch\n    \"KNN_K\": 3,\n    \"KNN_USE_SUBSET\": False,\n    \"KNN_SUBSET_SIZE\": 10000,\n\n    # SVM\n    \"SVM_KERNEL\": \"rbf\",\n    \"SVM_C\": 5,\n    \"SVM_GAMMA\": 0.05,\n    \"SVM_USE_SUBSET\": False,\n    \"SVM_SUBSET_SIZE\": 15000,\n\n    # Decision Tree\n    \"DT_MAX_DEPTH\": 20,\n    \"DT_MIN_SAMPLES_SPLIT\": 10,\n\n    # Misclassified\n    \"N_MISCLASSIFIED_SAVE\": 10\n}\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:39.403385Z\",\"iopub.execute_input\":\"2026-01-10T12:08:39.403813Z\",\"iopub.status.idle\":\"2026-01-10T12:08:39.421657Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:39.403771Z\",\"shell.execute_reply\":\"2026-01-10T12:08:39.420629Z\"}}\nBASE_OUTPUT = \"/kaggle/working/outputs\"\nBASE_MIS_DIR = os.path.join(BASE_OUTPUT, \"misclassified\")\n\nKNN_PCA_DIR = os.path.join(BASE_MIS_DIR, \"knn_pca\")\nSVM_PCA_DIR = os.path.join(BASE_MIS_DIR, \"svm_pca\")\nDT_DIR      = os.path.join(BASE_MIS_DIR, \"decision_tree\")\nENSEMBLE_DIR= os.path.join(BASE_MIS_DIR, \"ensemble\")\n\nos.makedirs(KNN_PCA_DIR, exist_ok=True)\nos.makedirs(SVM_PCA_DIR, exist_ok=True)\nos.makedirs(DT_DIR, exist_ok=True)\nos.makedirs(ENSEMBLE_DIR, exist_ok=True)\n\nprint(\"All outputs will be saved at:\", BASE_OUTPUT)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:39.422961Z\",\"iopub.execute_input\":\"2026-01-10T12:08:39.423407Z\",\"iopub.status.idle\":\"2026-01-10T12:08:43.310241Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:39.423378Z\",\"shell.execute_reply\":\"2026-01-10T12:08:43.309187Z\"}}\nTRAIN_PATH = \"/kaggle/input/mnist-in-csv/mnist_train.csv\"\nTEST_PATH  = \"/kaggle/input/mnist-in-csv/mnist_test.csv\"\n\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df  = pd.read_csv(TEST_PATH)\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape :\", test_df.shape)\n\nprint(\"Missing values train:\", train_df.isnull().sum().sum())\nprint(\"Missing values test :\", test_df.isnull().sum().sum())\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:43.311489Z\",\"iopub.execute_input\":\"2026-01-10T12:08:43.312137Z\",\"iopub.status.idle\":\"2026-01-10T12:08:43.827508Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:43.312101Z\",\"shell.execute_reply\":\"2026-01-10T12:08:43.826548Z\"}}\nprint(\"\\nTrain class distribution:\")\nprint(train_df.iloc[:, 0].value_counts().sort_index())\n\nplt.figure(figsize=(10,5))\nfor i in range(10):\n    img = train_df.iloc[i, 1:].values.reshape(28,28)\n    label = train_df.iloc[i, 0]\n\n    plt.subplot(2,5,i+1)\n    plt.imshow(img, cmap=\"gray\")\n    plt.title(f\"Label: {label}\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:43.828782Z\",\"iopub.execute_input\":\"2026-01-10T12:08:43.829178Z\",\"iopub.status.idle\":\"2026-01-10T12:08:44.001795Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:43.829121Z\",\"shell.execute_reply\":\"2026-01-10T12:08:44.000725Z\"}}\nX_train = train_df.iloc[:, 1:].values.astype(np.float32) / 255.0\ny_train = train_df.iloc[:, 0].values\n\nX_test  = test_df.iloc[:, 1:].values.astype(np.float32) / 255.0\ny_test  = test_df.iloc[:, 0].values\n\nprint(\"X_train:\", X_train.shape)\nprint(\"X_test :\", X_test.shape)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:44.002846Z\",\"iopub.execute_input\":\"2026-01-10T12:08:44.003141Z\",\"iopub.status.idle\":\"2026-01-10T12:08:44.730329Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:44.003113Z\",\"shell.execute_reply\":\"2026-01-10T12:08:44.729609Z\"}}\nif CONFIG[\"ENABLE_PCA\"]:\n    pca = PCA(n_components=CONFIG[\"PCA_COMPONENTS\"], random_state=42)\n    X_train_pca = pca.fit_transform(X_train)\n    X_test_pca  = pca.transform(X_test)\n\n    print(\"PCA Enabled \")\n    print(\"PCA Components:\", CONFIG[\"PCA_COMPONENTS\"])\n    print(\"Train PCA Shape:\", X_train_pca.shape)\n    print(\"Test PCA Shape:\", X_test_pca.shape)\nelse:\n    X_train_pca, X_test_pca = None, None\n    print(\"PCA Disabled \")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:44.731263Z\",\"iopub.execute_input\":\"2026-01-10T12:08:44.731565Z\",\"iopub.status.idle\":\"2026-01-10T12:08:44.742433Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:44.731534Z\",\"shell.execute_reply\":\"2026-01-10T12:08:44.741717Z\"}}\nclass FastKNNFromScratch:\n    def __init__(self, k=3):\n        self.k = k\n        \n    def fit(self, X, y):\n        self.X_train = X\n        self.y_train = y\n\n    def predict(self, X_test):\n        preds = []\n        for x in X_test:\n            distances = np.linalg.norm(self.X_train - x, axis=1)  # vectorized\n            k_idx = np.argsort(distances)[:self.k]\n            k_labels = self.y_train[k_idx]\n            preds.append(Counter(k_labels).most_common(1)[0][0])\n        return np.array(preds)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:08:44.746984Z\",\"iopub.execute_input\":\"2026-01-10T12:08:44.747304Z\",\"iopub.status.idle\":\"2026-01-10T12:11:13.248109Z\",\"shell.execute_reply.started\":\"2026-01-10T12:08:44.747272Z\",\"shell.execute_reply\":\"2026-01-10T12:11:13.247191Z\"}}\n# This code block lets user know whether PCA is being used or not\n\nif CONFIG[\"USE_PCA_FOR_KNN\"] and CONFIG[\"ENABLE_PCA\"]:\n    X_knn_train_full = X_train_pca\n    X_knn_test = X_test_pca\n    print(\"KNN using PCA\")\nelse:\n    X_knn_train_full = X_train\n    X_knn_test = X_test\n    print(\"KNN using RAW pixels\")\n\n# Optional subset\nif CONFIG[\"KNN_USE_SUBSET\"]:\n    X_knn_train = X_knn_train_full[:CONFIG[\"KNN_SUBSET_SIZE\"]]\n    y_knn_train = y_train[:CONFIG[\"KNN_SUBSET_SIZE\"]]\nelse:\n    X_knn_train = X_knn_train_full\n    y_knn_train = y_train\n\nknn_model = FastKNNFromScratch(k=CONFIG[\"KNN_K\"])\nknn_model.fit(X_knn_train, y_knn_train)\n\nstart = time.time()\ny_pred_knn = knn_model.predict(X_knn_test)\nknn_time = time.time() - start\n\nprint(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.4f} | Time: {knn_time:.2f}s\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:11:13.249324Z\",\"iopub.execute_input\":\"2026-01-10T12:11:13.249694Z\",\"iopub.status.idle\":\"2026-01-10T12:12:47.718722Z\",\"shell.execute_reply.started\":\"2026-01-10T12:11:13.249655Z\",\"shell.execute_reply\":\"2026-01-10T12:12:47.717971Z\"}}\n# This code block lets user know whether PCA is being used or not\n\nif CONFIG[\"USE_PCA_FOR_SVM\"] and CONFIG[\"ENABLE_PCA\"]:\n    X_svm_train_full = X_train_pca\n    X_svm_test = X_test_pca\n    print(\"SVM using PCA \")\nelse:\n    X_svm_train_full = X_train\n    X_svm_test = X_test\n    print(\"SVM using RAW pixels \")\n\n# Optional subset\nif CONFIG[\"SVM_USE_SUBSET\"]:\n    X_svm_train = X_svm_train_full[:CONFIG[\"SVM_SUBSET_SIZE\"]]\n    y_svm_train = y_train[:CONFIG[\"SVM_SUBSET_SIZE\"]]\nelse:\n    X_svm_train = X_svm_train_full\n    y_svm_train = y_train\n\nsvm_model = SVC(\n    kernel=CONFIG[\"SVM_KERNEL\"],\n    C=CONFIG[\"SVM_C\"],\n    gamma=CONFIG[\"SVM_GAMMA\"] if CONFIG[\"SVM_KERNEL\"] == \"rbf\" else \"scale\"\n)\n\nstart = time.time()\nsvm_model.fit(X_svm_train, y_svm_train)\ny_pred_svm = svm_model.predict(X_svm_test)\nsvm_time = time.time() - start\n\nprint(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.4f} | Time: {svm_time:.2f}s\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:12:47.719845Z\",\"iopub.execute_input\":\"2026-01-10T12:12:47.720124Z\",\"iopub.status.idle\":\"2026-01-10T12:13:06.345640Z\",\"shell.execute_reply.started\":\"2026-01-10T12:12:47.720098Z\",\"shell.execute_reply\":\"2026-01-10T12:13:06.344841Z\"}}\n# This code block lets user know whether PCA is being used or not(its off by deafault for DT)\n\nif CONFIG[\"USE_PCA_FOR_DT\"] and CONFIG[\"ENABLE_PCA\"]:\n    X_dt_train = X_train_pca\n    X_dt_test  = X_test_pca\n    print(\"Decision Tree using PCA \")\nelse:\n    X_dt_train = X_train\n    X_dt_test  = X_test\n    print(\"Decision Tree using RAW pixels \")\n\ndt_model = DecisionTreeClassifier(\n    max_depth=CONFIG[\"DT_MAX_DEPTH\"],\n    min_samples_split=CONFIG[\"DT_MIN_SAMPLES_SPLIT\"],\n    random_state=42\n)\n\nstart = time.time()\ndt_model.fit(X_dt_train, y_train)\ny_pred_dt = dt_model.predict(X_dt_test)\ndt_time = time.time() - start\n\nprint(f\"Decision Tree Accuracy: {accuracy_score(y_test, y_pred_dt):.4f} | Time: {dt_time:.2f}s\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:13:06.346606Z\",\"iopub.execute_input\":\"2026-01-10T12:13:06.346915Z\",\"iopub.status.idle\":\"2026-01-10T12:13:06.406510Z\",\"shell.execute_reply.started\":\"2026-01-10T12:13:06.346877Z\",\"shell.execute_reply\":\"2026-01-10T12:13:06.405820Z\"}}\nensemble_preds = np.vstack([\n    y_pred_knn,\n    y_pred_svm,\n    y_pred_dt\n])\n\ny_pred_ensemble = np.array([\n    Counter(ensemble_preds[:, i]).most_common(1)[0][0]\n    for i in range(ensemble_preds.shape[1])\n])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:13:06.407483Z\",\"iopub.execute_input\":\"2026-01-10T12:13:06.407726Z\",\"iopub.status.idle\":\"2026-01-10T12:13:06.419241Z\",\"shell.execute_reply.started\":\"2026-01-10T12:13:06.407702Z\",\"shell.execute_reply\":\"2026-01-10T12:13:06.418328Z\"}}\ndef evaluate_model(name, y_true, y_pred):\n    \"\"\"\n    Prints Accuracy, Classification Report, Confusion Matrix Heatmap\n    \"\"\"\n    acc = accuracy_score(y_true, y_pred)\n    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_true, y_pred))\n\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.title(f\"{name} Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n\n    return acc\n\n\ndef save_misclassified(name, y_true, y_pred, X_images, save_dir, prefix, n_save=10):\n    \"\"\"\n    Saves and displays misclassified images + saves summary CSV.\n    \"\"\"\n    mis_idx = np.where(y_true != y_pred)[0]\n    print(f\"\\nTotal misclassified ({name}): {len(mis_idx)}\")\n\n    # Show first N misclassified images\n    show_idx = mis_idx[:n_save]\n\n    plt.figure(figsize=(12,5))\n    for i, idx in enumerate(show_idx):\n        img = X_images[idx].reshape(28,28)\n        t = y_true[idx]\n        p = y_pred[idx]\n\n        plt.subplot(2,5,i+1)\n        plt.imshow(img, cmap=\"gray\")\n        plt.title(f\"T:{t} P:{p}\")\n        plt.axis(\"off\")\n\n        # Save image\n        plt.imsave(\n            os.path.join(save_dir, f\"{prefix}_{i}_T{t}_P{p}.png\"),\n            img,\n            cmap=\"gray\"\n        )\n\n    plt.tight_layout()\n    plt.show()\n    print(f\"Saved {len(show_idx)} images to: {save_dir}\")\n\n    # Create and save misclassification summary\n    mis_pairs = [(y_true[idx], y_pred[idx]) for idx in mis_idx]\n    mis_df = pd.DataFrame(mis_pairs, columns=[\"True\", \"Predicted\"])\n    summary = mis_df.value_counts().reset_index(name=\"Count\").sort_values(\"Count\", ascending=False)\n\n    summary_path = f\"/kaggle/working/outputs/{prefix}_misclassification_summary.csv\"\n    summary.to_csv(summary_path, index=False)\n\n    print(\"Saved summary CSV to:\", summary_path)\n    display(summary.head(10))\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:13:06.420541Z\",\"iopub.execute_input\":\"2026-01-10T12:13:06.420942Z\",\"iopub.status.idle\":\"2026-01-10T12:13:07.793278Z\",\"shell.execute_reply.started\":\"2026-01-10T12:13:06.420899Z\",\"shell.execute_reply\":\"2026-01-10T12:13:07.792431Z\"}}\nevaluate_model(\"KNN\", y_test, y_pred_knn)\nevaluate_model(\"SVM\", y_test, y_pred_svm)\nevaluate_model(\"Decision Tree\", y_test, y_pred_dt)\nevaluate_model(\"Voting Ensemble\", y_test, y_pred_ensemble)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-01-10T12:13:07.794595Z\",\"iopub.execute_input\":\"2026-01-10T12:13:07.794984Z\",\"iopub.status.idle\":\"2026-01-10T12:13:10.148927Z\",\"shell.execute_reply.started\":\"2026-01-10T12:13:07.794947Z\",\"shell.execute_reply\":\"2026-01-10T12:13:10.147976Z\"}}\nN_SAVE = CONFIG[\"N_MISCLASSIFIED_SAVE\"]\n\nsave_misclassified(\"KNN\", y_test, y_pred_knn, X_test, KNN_PCA_DIR, \"knn\", N_SAVE)\nsave_misclassified(\"SVM\", y_test, y_pred_svm, X_test, SVM_PCA_DIR, \"svm\", N_SAVE)\nsave_misclassified(\"Decision Tree\", y_test, y_pred_dt, X_test, DT_DIR, \"dt\", N_SAVE)\nsave_misclassified(\"Ensemble\",y_test, y_pred_ensemble, X_test, ENSEMBLE_DIR,\"ensemble\", N_SAVE)\n\n# %% [markdown]\n# # **Flowchart**\n# \n# 1. Import required libraries\n# 2. Load train.csv and test.csv\n# 3. Data exploration\n# 4. Dataset size + class distribution\n# 5. Display sample images 28x28\n# 6. Check missing values\n# 7. Normalize pixels 0-255 to 0-1\n# 8. Define tunable hyperparameters\n# 9. If PCA Enabled convert the 784 dimensions to n_components dimensions\n# 10. If PCA is not enabled Use raw 784 pixel features\n# 11. Training of all models(KNN, SVM and Decision Tree)\n# 12. Evaluations of all the models on the test dataset\n# 13. Calculating the accuracy of each model\n# 14. Confusion matrix heatmaps and classification report\n# 15. Misclassified analysis\n# 16. Save misclassified images\n# 17. Save confusion-pair summary CSV\n# 18. Final report\n\n# %% [markdown]\n# # **Observations and Conclusion:**\n# \n# This project implements a classical machine learning pipeline to classify handwritten digits (0–9) using MNIST CSV images. The dataset was explored by viewing sample images and class distribution, and pixel values were normalized to the range 0–1. PCA was optionally applied to reduce dimensionality, improving computational efficiency for KNN and SVM. KNN was implemented fully from scratch using Euclidean distance and majority voting. A vectorized “Fast KNN” version was used instead of a loop-based simple implementation to reduce runtime while keeping the same algorithm. Simple KNN was slow on the training dataset so a FastKNN version was implemented for faster training as the training dataset was large(60000).\n# \n# Among the models, SVM generally achieved the best accuracy due to stronger decision boundaries, while Decision Tree trained quickly but produced more errors due to overfitting.\n# The use of subset hyperparameter was not implemented(it was kept Fasle) during the final analysis for both SVM or KNN as it reduced the training samples and reduced the accuracy of the models and caused them to misclassify more digits. \n# \n# During the training of models, both Simple and Fast KNN architecure were trained with PCA. Even though PCA was enabled the simple version of KNN took longer time to train(approx. 50 mins) while the fast KNN trained within minutes. there was no noticeable difference between the accuracies of these two models with PCA enabled. The only difference was time so in this notebook only the fast KNN model is used.\n# \n# Decision tree model performed the least accurately amongst these 3 models. Hyperparameter tuning was done to see the effect of various configurations. The best configuration found was the final one on which the number of misclassified digits were recorded.\n# \n# Misclassifications frequently occurred between visually similar digits such as 4 and 9 or 3 and 5 3 and 8 and so on. Misclassification of digits usually happened between digits which were poorly written and the ones which have similar strokes while writing. The voting ensemble improved stability by combining predictions from multiple models. Further improvements could include tuning PCA components, optimizing hyperparameters, and applying weighted voting.\n# \n# This notebook was run using kaggle and the dataset was directly attached to the input of this notebook. \n\n# %% [code]\n","metadata":{"_uuid":"73a6de97-fd43-4172-9d87-c581b8873b56","_cell_guid":"6cc15100-06f7-402d-963d-0444f3e5a38b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}